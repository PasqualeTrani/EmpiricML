{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#empiricml","title":"EmpiricML","text":"<p>EmpiricML is an open-source Python framework designed to bring the rigor of empirical science to the Machine Learning development process. Are you tired of scattered Jupyter Notebooks and untracked experiments? EmpiricML provides a structured \"Laboratory\" environment to help you move from messy scripts to reproducible science.</p>"},{"location":"#the-philosophy-ml-as-an-empirical-science","title":"The Philosophy: ML as an Empirical Science","text":"<p>The core idea behind EmpiricML is that building a machine learning model is an iterative, scientific process. You form a hypothesis (e.g., \"Adding these specific features will decrease the error\"), and you must test it in a controlled environment. EmpiricML provides that environment through the Lab class. It encapsulates everything needed for rigorous ML experimentation:</p> <ul> <li>Train and test data management</li> <li>Cross-validation strategies</li> <li>Evaluation metrics</li> <li>Standardized criteria for comparing models</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#experiment-tracking","title":"Experiment Tracking","text":"<p>Keep a detailed ledger of every run. EmpiricML automatically stores:</p> <ul> <li>Metric performance and overfitting percentages</li> <li>Training and inference latency</li> <li>Generated predictions for downstream analysis</li> </ul>"},{"location":"#polars-native-pipelines","title":"Polars-Native Pipelines","text":"<p>Performance is at the heart of EmpiricML. Unlike scikit-learn pipelines which are NumPy-based, EmpiricML transformations utilize Polars LazyFrames. This allows for lightning-fast, memory-efficient data handling even with large datasets.</p>"},{"location":"#automated-workflows","title":"Automated Workflows","text":"<p>Stop writing boilerplate code for standard tasks. EmpiricML automates:</p> <ul> <li>Hyperparameter Optimization (HPO)</li> <li>Feature Importance calculation</li> <li>Automated Feature Selection</li> </ul>"},{"location":"#rigorous-model-comparison","title":"Rigorous Model Comparison","text":"<p>Compare experiments with statistical confidence. Define comparison criteria in your Lab class based on:</p> <p>Performance Thresholds: Does Model B outperform Model A by a significant margin? Statistical Tests: Use built-in tests to ensure your improvements aren't just noise</p> <p>EmpiricML can automatically update and store your \"Best Model\" based on these predefined rules.</p>"},{"location":"#fast-ml-baselines","title":"Fast ML Baselines","text":"<p>Go from zero to a leaderboard in seconds. With just a few lines of code, you can evaluate up to 10 baseline models (including LightGBM, XGBoost, Random Forest, MLP, and more) to establish a performance floor for your project.</p> <p>### Early Stopping  Aborts unpromising experiments early to save compute resources.</p>"},{"location":"#checkpointing","title":"Checkpointing","text":"<p>Save/Restore your <code>Lab</code> state to pause and resume work seamlessly.</p>"},{"location":"api/","title":"API Reference","text":"<p>This is the class and function reference of EmpiricML. Please select a module from the navigation menu or the table below to view its documentation.</p> Module Description <code>empml.base</code> Core abstract base classes for building other components. <code>empml.cv</code> Cross-validation splitting strategies and utilities. <code>empml.data</code> Classes for downloading and loading data. <code>empml.errors</code> Custom exceptions used throughout the framework. <code>empml.lab</code> The main experimentation framework for model development. <code>empml.metrics</code> Performance metrics for regression and classification. <code>empml.pipeline</code> Pipeline orchestration and evaluation tools. <code>empml.transformers</code> Feature engineering transformers compatible with Polars. <code>empml.wrappers</code> Wrappers for integrating Scikit-learn and PyTorch models."},{"location":"contributing/","title":"Contributing to EmpiricML","text":"<p>I appreciate your interest in contributing to EmpiricML! This guide will help you get started with reporting issues and extending the framework.</p>"},{"location":"contributing/#1-reporting-issues","title":"1. Reporting Issues","text":"<p>If you encounter any bugs, have feature requests, or want to suggest improvements, please use the GitHub Issues tracker.</p>"},{"location":"contributing/#bug-reports","title":"Bug Reports","text":"<p>When reporting a bug, please include:</p> <ul> <li>A clear and descriptive title.</li> <li>A detailed description of the issue.</li> <li>Steps to reproduce the bug (including code snippets if possible).</li> <li>The expected behavior vs. the actual behavior.</li> <li>Your environment details (OS, Python version, EmpiricML version).</li> </ul>"},{"location":"contributing/#feature-requests","title":"Feature Requests","text":"<p>For feature requests, please provide:</p> <ul> <li>A clear description of the proposed feature.</li> <li>The motivation behind the feature (why is it needed?).</li> <li>Potential implementation details (if you have ideas).</li> </ul>"},{"location":"contributing/#2-extending-classes","title":"2. Extending Classes","text":"<p>EmpiricML is built to be modular and extensible. You can easily plug in new components by inheriting from the base classes defined in <code>empml.base</code>.</p>"},{"location":"contributing/#data-downloaders","title":"Data Downloaders","text":"<p>If you need to load data from sources not currently supported (e.g., S3, PostgreSQL, Amazon Redshift, SharePoint, etc.), you can create a custom downloader by extending the <code>DataDownloader</code> class.</p> <p>You need to implement the <code>get_data</code> method, which must return a <code>polars.LazyFrame</code>.</p>"},{"location":"contributing/#example-creating-a-postgresql-downloader","title":"Example: Creating a PostgreSQL Downloader","text":"<pre><code>import polars as pl\nfrom empml.base import DataDownloader\n\nclass PostgresDownloader(DataDownloader):\n    \"\"\"\n    Custom downloader for PostgreSQL databases.\n    \"\"\"\n    def __init__(self, connection_uri: str, query: str):\n        self.connection_uri = connection_uri\n        self.query = query\n\n    def get_data(self) -&gt; pl.LazyFrame:\n        \"\"\"\n        Reads data from PostgreSQL and returns a Polars LazyFrame.\n        \"\"\"\n        return pl.read_database_uri(\n            query=self.query,\n            uri=self.connection_uri\n        ).lazy()\n</code></pre>"},{"location":"contributing/#transformers","title":"Transformers","text":"<p>To add new data transformation logic (e.g., Clustering, dimensionality reduction, or custom feature engineering), you should extend the <code>BaseTransformer</code> class.</p> <p>You must implement two methods:</p> <ol> <li><code>fit(self, lf: pl.LazyFrame)</code>: Learns parameters from the data (if stateful).</li> <li><code>transform(self, lf: pl.LazyFrame) -&gt; pl.LazyFrame</code>: Applies the transformation.</li> </ol>"},{"location":"contributing/#example-creating-a-custom-transformer","title":"Example: Creating a Custom Transformer","text":"<pre><code>import polars as pl\nfrom empml.base import BaseTransformer\n\nclass MyTransformer(BaseTransformer):\n    \"\"\"\n    A generic transformer template.\n    Replace this with your custom transformation logic.\n    \"\"\"\n    def __init__(self, param1: str, param2: int = 10):\n        \"\"\"\n        Initialize your transformer with any parameters needed.\n\n        Args:\n            param1: Description of parameter 1\n            param2: Description of parameter 2\n        \"\"\"\n        self.param1 = param1\n        self.param2 = param2\n        # Add any attributes that will be learned during fit\n        self.fitted_value_ = None\n\n    def fit(self, lf: pl.LazyFrame):\n        \"\"\"\n        Learn parameters from the data if needed.\n        For stateless transformers, this can simply return self.\n\n        Args:\n            lf: Input Polars LazyFrame\n\n        Returns:\n            self\n        \"\"\"\n        # Example: compute and store some statistic from the data\n        # self.fitted_value_ = lf.select(pl.col(self.param1).mean()).collect().item()\n\n        return self\n\n    def transform(self, lf: pl.LazyFrame) -&gt; pl.LazyFrame:\n        \"\"\"\n        Apply the transformation to the data.\n\n        Args:\n            lf: Input Polars LazyFrame\n\n        Returns:\n            Transformed Polars LazyFrame\n        \"\"\"\n        # Example: add a new column based on your transformation logic\n        # return lf.with_columns(\n        #     (pl.col(self.param1) * self.param2).alias(\"new_feature\")\n        # )\n\n        return lf\n</code></pre> <p>By following these patterns, you can integrate virtually any custom logic into the EmpiricML pipeline.</p> <p>If you create a custom transformer or a custom downloader not included in the framework, please consider submitting a pull request to add it. Thank you!</p>"},{"location":"examples/","title":"Examples","text":"<p>This section demonstrates the core functionalities of the <code>Lab</code> class for managing machine learning experiments.</p>"},{"location":"examples/#1-initializing-lab","title":"1. Initializing Lab","text":"<p>The <code>Lab</code> class is the central orchestrator. It requires a data source, an evaluation metric, a cross-validation strategy, and comparison criteria.</p> <pre><code>from empml.lab import Lab, ComparisonCriteria\nfrom empml.data import ParquetDownloader\nfrom empml.cv import KFold\nfrom empml.metrics import RMSE\n\n# Initialize the Lab environment\nlab = Lab(\n    train_downloader=ParquetDownloader('./data/train.parquet'),\n    metric=RMSE(),\n    cv_generator=KFold(n_splits=5, random_state=7),\n    target='target_column',\n    comparison_criteria=ComparisonCriteria(\n        n_folds_threshold=2, # Experiment considered better if it improves &gt;2 folds\n        pct_threshold=0.01   # and improves metric by at least 1%\n    ),\n    minimize=True,  # True for errors (RMSE), False for scores (Accuracy)\n    row_id='row_id' # Unique identifier for each row\n)\n</code></pre>"},{"location":"examples/#2-running-a-pipeline-experiment","title":"2. Running a Pipeline Experiment","text":"<p>Create a pipeline typically involving transformers and a model wrapper, then run it.</p> <pre><code>from lightgbm import LGBMRegressor\nfrom empml.pipeline import Pipeline\nfrom empml.wrappers import SKlearnWrapper\nfrom empml.transformers import Log1pFeatures\n\n# Define a pipeline with feature engineering and model\npipeline = Pipeline([\n    ('log_features', Log1pFeatures(features=['feature1', 'feature2'])),\n    ('model', SKlearnWrapper(\n        estimator=LGBMRegressor(verbose=-1),\n        features=['feature1', 'feature2', 'feature3'],\n        target='target_column'\n    ))\n], name='LGBM_Experiment', description='LGBM with Log1p transformation')\n\n# Run the experiment\nlab.run_experiment(pipeline)\n</code></pre>"},{"location":"examples/#3-running-base-experiments","title":"3. Running Base Experiments","text":"<p>Run a suite of default baseline models (Linear Regression, KNN, Random Forest, etc.) to establish performance benchmarks.</p> <pre><code># Run a suite of baseline models\nlab.run_base_experiments(\n    features=['feature1', 'feature2', 'feature3'],\n    problem_type='regression' # or 'classification'\n)\n</code></pre>"},{"location":"examples/#4-setting-the-best-experiment","title":"4. Setting the Best Experiment","text":"<p>Mark a specific experiment as the current \"best\" to compare future experiments against.</p> <pre><code># Manually set the best experiment ID (e.g., ID 1)\nlab._set_best_experiment(experiment_id=1)\n</code></pre>"},{"location":"examples/#5-comparing-against-best-experiment","title":"5. Comparing Against Best Experiment","text":"<p>Run a new experiment and automatically compare it against the set baseline.</p> <pre><code># Define another pipeline with different parameters\npipeline_v2 = Pipeline([\n    ('model', SKlearnWrapper(\n        estimator=LGBMRegressor(n_estimators=200, verbose=-1),\n        features=['feature1', 'feature2', 'feature3'],\n        target='target_column'\n    ))\n], name='LGBM_v2')\n\n# Run and compare against the best experiment (ID 1)\nlab.run_experiment(pipeline_v2, compare_against=1)\n\n# Alternatively, use auto_mode to automatically compare against the current best experiment\n# and update the best_experiment attribute if the new pipeline performs better according to the comparison criteria\nlab._set_best_experiment(1)\nlab.run_experiment(pipeline_v2, auto_mode=True)\n</code></pre>"},{"location":"examples/#6-hyperparameter-optimization-hpo","title":"6. Hyperparameter Optimization (HPO)","text":"<p>Perform grid or random search over a managed search space.</p> <pre><code># Define hyperparameter search space\nparams_list = {\n    'n_estimators': [100, 200, 500],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'num_leaves': [31, 64]\n}\n\n# Launch optimization\nbest_result = lab.hpo(\n    features=['feature1', 'feature2', 'feature3'],\n    params_list=params_list,\n    estimator=LGBMRegressor,\n    search_type='random',\n    num_samples=10,\n    store_preds=False\n)\n</code></pre>"},{"location":"examples/#7-permutation-feature-importance","title":"7. Permutation Feature Importance","text":"<p>Analyze which features contribute most to the model's performance.</p> <pre><code># Retrieve the best pipeline\npipeline = lab.retrieve_pipeline(experiment_id=1)\n\n# Calculate feature importance\npfi : pl.DataFrame= lab.permutation_feature_importance(\n    pipeline=pipeline,\n    features=['feature1', 'feature2', 'feature3'],\n    n_iters=5\n)\n\npfi\n</code></pre>"},{"location":"examples/#8-retrieving-predictions-error-analysis","title":"8. Retrieving Predictions &amp; Error Analysis","text":"<p>Load out-of-fold predictions to analyze where the model fails.</p> <pre><code>import polars as pl\n\n# Retrieve predictions from specific experiments\npreds = lab.retrieve_predictions(\n    experiment_ids=[1], # list of experiment IDs\n    extra_features=['date'] # Optional: add extra columns from training data\n)\n</code></pre>"},{"location":"install/","title":"Install","text":""},{"location":"install/#installation","title":"Installation","text":"<p>EmpiricML is available on PyPI and can be installed using pip:</p> <pre><code>pip install empiricml\n</code></pre> <p>Requirements: Python 3.11 or higher.</p>"},{"location":"install/#dependencies","title":"Dependencies","text":"<p>When you install EmpiricML, the following dependencies will be automatically installed:</p> <ul> <li><code>numpy&gt;=1.26.4</code></li> <li><code>pandas&gt;=2.2.2</code></li> <li><code>pyarrow&gt;=15.0.2</code></li> <li><code>polars&gt;=1.31.0</code></li> <li><code>matplotlib&gt;=3.9.0</code></li> <li><code>scikit-learn&gt;=1.7.1</code></li> <li><code>lightgbm&gt;=4.6.0</code></li> <li><code>xgboost&gt;=3.1.2</code></li> <li><code>catboost&gt;=1.2.8</code></li> <li><code>skorch&gt;=1.3.1</code></li> </ul>"},{"location":"install/#pytorch-support","title":"PyTorch Support","text":"<p>EmpiricML supports PyTorch models through the <code>TorchWrapper</code> class. However, PyTorch is not installed automatically to allow users to choose the specific version that matches their hardware configuration (CPU vs GPU, CUDA version, etc.).</p> <p>To use PyTorch models with EmpiricML:</p> <ol> <li>Install PyTorch separately by following the instructions on the official PyTorch website.</li> <li>Use the <code>TorchWrapper</code> class to integrate your PyTorch models into the EmpiricML workflow.</li> </ol>"},{"location":"api/base/","title":"empml.base","text":"Object Description <code>DataDownloader</code> Abstract class for downloading data into Polars LazyFrames. <code>CVGenerator</code> Abstract base class for cross-validation splitting strategies. <code>Metric</code> Abstract base class for performance metrics. <code>BaseTransformer</code> Abstract base class for transformers that work with Polars LazyFrames. <code>BaseEstimator</code> Abstract base class for estimators that work with Polars LazyFrames. <code>SKlearnEstimator</code> Protocol for sklearn-like estimators."},{"location":"api/base/#datadownloader","title":"DataDownloader","text":"<p>Abstract class for downloading data into Polars LazyFrames.</p>"},{"location":"api/base/#abstract-methods","title":"Abstract Methods","text":"<pre><code>@abstractmethod\ndef get_data(self) -&gt; pl.LazyFrame:\n    pass\n</code></pre>"},{"location":"api/base/#cvgenerator","title":"CVGenerator","text":"<p>Abstract base class for cross-validation splitting strategies.</p>"},{"location":"api/base/#abstract-methods_1","title":"Abstract Methods","text":"<pre><code>@abstractmethod\ndef split(self, lf : pl.LazyFrame, row_id : str) -&gt; List[Tuple[np.array]]:\n    \"\"\"Generate a list of tuple with two elements: the first one is an array containing the row indexes for the train dataset, while the second contains the row indexes for the validation dataset\"\"\"\n    pass \n</code></pre>"},{"location":"api/base/#metric","title":"Metric","text":"<p>Abstract base class for performance metrics.</p>"},{"location":"api/base/#abstract-methods_2","title":"Abstract Methods","text":"<pre><code>@abstractmethod\ndef compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    \"\"\"\n    Computes the metric, strictly requiring a Polars LazyFrame as input.\n    The final calculation executes the lazy plan to return a scalar float.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base/#basetransformer","title":"BaseTransformer","text":"<p>Abstract base class for transformers that work with Polars LazyFrames.</p>"},{"location":"api/base/#abstract-methods_3","title":"Abstract Methods","text":"<pre><code>@abstractmethod\ndef fit(self, lf: pl.LazyFrame):\n    \"\"\"Fit the transformer on the data.\"\"\"\n    pass\n\n@abstractmethod\ndef transform(self, lf: pl.LazyFrame) -&gt; pl.LazyFrame:\n    \"\"\"Transform the data.\"\"\"\n    pass\n</code></pre>"},{"location":"api/base/#baseestimator","title":"BaseEstimator","text":"<p>Abstract base class for estimators that work with Polars LazyFrames.</p>"},{"location":"api/base/#abstract-methods_4","title":"Abstract Methods","text":"<pre><code>@abstractmethod\ndef fit(self, df : pl.LazyFrame):\n    \"\"\"Fit the estimator on the data.\"\"\"\n    pass\n\n@abstractmethod\ndef predict(self, df : pl.LazyFrame):\n    \"\"\"Predict by using the fitted estimator.\"\"\"\n    pass\n</code></pre>"},{"location":"api/base/#sklearnestimator","title":"SKlearnEstimator","text":"<p>Protocol for sklearn-like estimators.</p>"},{"location":"api/base/#protocol-methods","title":"Protocol Methods","text":"<pre><code>def fit(self, X: np.ndarray, y: np.ndarray, **kwargs) -&gt; Any:\n    \"\"\"Fit the estimator.\"\"\"\n    ...\n\ndef predict(self, X: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Make predictions.\"\"\"\n    ...\n</code></pre>"},{"location":"api/cv/","title":"empml.cv","text":"Object Description <code>KFold</code> Standard K-Fold cross-validation with random shuffling. <code>StratifiedKFold</code> Stratified K-Fold that preserves class distribution across folds. <code>GroupKFold</code> Group K-Fold that prevents data leakage between groups. <code>LeaveOneGroupOut</code> Leave-One-Group-Out cross-validation. <code>TimeSeriesSplit</code> Time series cross-validation generator that splits data based on date ranges. <code>TrainTestSplit</code> Single train-test split with random shuffling."},{"location":"api/cv/#kfold","title":"KFold","text":"<p>Standard K-Fold cross-validation with random shuffling.</p>"},{"location":"api/cv/#methods","title":"Methods","text":"<pre><code>def __init__(self, n_splits: int = 5, random_state: int = None):\n    pass\n\ndef split(self, lf: pl.LazyFrame, row_id: str) -&gt; List[Tuple[np.array]]:\n    \"\"\"\n    Generate k-fold train/validation splits.\n\n    Parameters\n    ----------\n    lf : pl.LazyFrame\n        Input data to split.\n    row_id : str\n        Column name containing unique row identifiers.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray]]\n        List of (train_indices, validation_indices) tuples for each fold.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/cv/#stratifiedkfold","title":"StratifiedKFold","text":"<p>Stratified K-Fold that preserves class distribution across folds.</p>"},{"location":"api/cv/#methods_1","title":"Methods","text":"<pre><code>def __init__(self, target_col: str, n_splits: int = 5, random_state: int = None):\n    pass\n\ndef split(self, lf: pl.LazyFrame, row_id: str) -&gt; List[Tuple[np.array]]:\n    \"\"\"\n    Generate stratified k-fold train/validation splits.\n\n    Parameters\n    ----------\n    lf : pl.LazyFrame\n        Input data to split.\n    row_id : str\n        Column name containing unique row identifiers.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray]]\n        List of (train_indices, validation_indices) tuples for each fold.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/cv/#groupkfold","title":"GroupKFold","text":"<p>Group K-Fold that prevents data leakage between groups.</p>"},{"location":"api/cv/#methods_2","title":"Methods","text":"<pre><code>def __init__(self, group_col: str, n_splits: int = 5, random_state: int = None):\n    pass\n\ndef split(self, lf: pl.LazyFrame, row_id: str) -&gt; List[Tuple[np.array]]:\n    \"\"\"\n    Generate group-aware k-fold train/validation splits.\n\n    Parameters\n    ----------\n    lf : pl.LazyFrame\n        Input data to split.\n    row_id : str\n        Column name containing unique row identifiers.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray]]\n        List of (train_indices, validation_indices) tuples for each fold.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/cv/#leaveonegroupout","title":"LeaveOneGroupOut","text":"<p>Leave-One-Group-Out cross-validation.</p>"},{"location":"api/cv/#methods_3","title":"Methods","text":"<pre><code>def __init__(self, group_col: str):\n    pass\n\ndef split(self, lf: pl.LazyFrame, row_id: str) -&gt; List[Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Generate leave-one-group-out train/validation splits.\n\n    Parameters\n    ----------\n    lf : pl.LazyFrame\n        Input data to split.\n    row_id : str\n        Column name containing unique row identifiers.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray]]\n        List of (train_indices, validation_indices) tuples, one per group.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/cv/#timeseriessplit","title":"TimeSeriesSplit","text":"<p>Time series cross-validation generator that splits data based on date ranges.</p>"},{"location":"api/cv/#methods_4","title":"Methods","text":"<pre><code>def __init__(self, windows: List[Tuple[str, str, str, str]], date_col: str):\n    \"\"\"\n    Initialize the TimeSeriesSplit cross-validator.\n\n    Parameters\n    ----------\n    windows : List[Tuple[str, str, str, str]]\n        List of date range tuples defining train/validation splits for each fold.\n        Each tuple contains (train_start, train_end, val_start, val_end).\n    date_col : str\n        Name of the date/timestamp column in the dataset.\n    \"\"\"\n    pass\n\ndef split(self, lf: pl.LazyFrame, row_id: str) -&gt; List[Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Generate train/validation row indices for each fold based on date windows.\n\n    Parameters\n    ----------\n    lf : pl.LazyFrame\n        Input data containing the date column and row identifier.\n    row_id : str\n        Name of the column containing unique row identifiers.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray]]\n        List of tuples, one per fold, where each tuple contains:\n        - train_indices: numpy array of row IDs for training\n        - val_indices: numpy array of row IDs for validation\n\n    Notes\n    -----\n    - If date_col is not already datetime type, it will be automatically converted\n      from string format using polars' str.to_datetime() method.\n    - Date filtering uses inclusive start (&gt;=) and exclusive end (&lt;) boundaries.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/cv/#traintestsplit","title":"TrainTestSplit","text":"<p>Single train-test split with random shuffling.</p>"},{"location":"api/cv/#methods_5","title":"Methods","text":"<pre><code>def __init__(self, test_size: float = 0.2, random_state: int = None):\n    pass\n\ndef split(self, lf: pl.LazyFrame, row_id: str) -&gt; List[Tuple[np.ndarray, np.ndarray]]:\n    \"\"\"\n    Generate single train/test split.\n\n    Parameters\n    ----------\n    lf : pl.LazyFrame\n        Input data to split.\n    row_id : str\n        Column name containing unique row identifiers.\n\n    Returns\n    -------\n    List[Tuple[np.ndarray, np.ndarray]]\n        Single-element list containing (train_indices, test_indices) tuple.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/data/","title":"empml.data","text":"Object Description <code>CSVDownloader</code> Class for reading a CSV file and returning a Polars LazyFrame. <code>ParquetDownloader</code> Class for reading a Parquet file and returning a Polars LazyFrame. <code>ExcelDownloader</code> Class for reading an Excel file and returning a Polars LazyFrame."},{"location":"api/data/#csvdownloader","title":"CSVDownloader","text":"<p>Class for reading a CSV file and returning a Polars LazyFrame.</p>"},{"location":"api/data/#methods","title":"Methods","text":"<pre><code>def __init__(self, path : str, separator : str = ';'):\n    pass\n\ndef get_data(self) -&gt; pl.LazyFrame:\n    return pl.scan_csv(self.path, separator = self.separator)\n</code></pre>"},{"location":"api/data/#parquetdownloader","title":"ParquetDownloader","text":"<p>Class for reading a Parquet file and returning a Polars LazyFrame.</p>"},{"location":"api/data/#methods_1","title":"Methods","text":"<pre><code>def __init__(self, path : str):\n    pass\n\ndef get_data(self) -&gt; pl.LazyFrame:\n    return pl.scan_parquet(self.path)\n</code></pre>"},{"location":"api/data/#exceldownloader","title":"ExcelDownloader","text":"<p>Class for reading an Excel file and returning a Polars LazyFrame.</p>"},{"location":"api/data/#methods_2","title":"Methods","text":"<pre><code>def __init__(self, path : str, sheet_name : str | None = None):\n    pass\n\ndef get_data(self) -&gt; pl.LazyFrame:\n    return pl.read_excel(self.path, sheet_name = self.sheet_name).lazy()\n</code></pre>"},{"location":"api/errors/","title":"empml.errors","text":"Object Description <code>RunExperimentConfigException</code> Exception raised for invalid experiment configurations. <code>RunExperimentOnTestException</code> Exception raised when errors occur during testing on the test set."},{"location":"api/errors/#runexperimentconfigexception","title":"RunExperimentConfigException","text":"<p>Exception raised for invalid experiment configurations.</p>"},{"location":"api/errors/#runexperimentontestexception","title":"RunExperimentOnTestException","text":"<p>Exception raised when errors occur during testing on the test set.</p>"},{"location":"api/lab/","title":"empml.lab","text":"Object Description <code>ComparisonCriteria</code> Statistical criteria for comparing experiment performance. <code>Lab</code> Experimentation framework for ML model development and evaluation."},{"location":"api/lab/#comparisoncriteria","title":"ComparisonCriteria","text":"<p>Statistical criteria for comparing experiment performance.</p>"},{"location":"api/lab/#attributes","title":"Attributes","text":"<ul> <li><code>n_folds_threshold</code>: Integer. Number of folds where the new model is allowed to perform worse than the baseline.</li> <li><code>pct_threshold</code>: Float (optional). Minimum percentage improvement required to consider a new model better.</li> <li><code>alpha</code>: Float (optional). Significance level for statistical testing.</li> <li><code>n_iters</code>: Integer (optional). Number of iterations for permutation testing.</li> </ul>"},{"location":"api/lab/#lab","title":"Lab","text":"<p>Experimentation framework for ML model development and evaluation. Manages experiment lifecycle: data loading, CV splitting, pipeline execution, results tracking, and statistical comparison. Supports HPO and feature selection.</p>"},{"location":"api/lab/#initialization","title":"Initialization","text":"<pre><code>def __init__(\n    self,\n    train_downloader: DataDownloader,\n    metric: Metric,\n    cv_generator: CVGenerator,\n    target: str,\n    comparison_criteria : ComparisonCriteria,\n    minimize: bool = True,\n    row_id: str | None = None,\n    test_downloader: DataDownloader | None = None,\n    name: str | None = None\n)\n</code></pre> <p>Parameters</p> <ul> <li><code>train_downloader</code>: Source for training data.</li> <li><code>metric</code>: Performance metric for evaluation.</li> <li><code>cv_generator</code>: Cross-validation splitting strategy.</li> <li><code>target</code>: Name of target column.</li> <li><code>comparison_criteria</code>: Statistical criteria for experiment comparison.</li> <li><code>minimize</code>: Whether to minimize metric (default True).</li> <li><code>row_id</code>: Column name for row identifier.</li> <li><code>test_downloader</code>: Optional test data source.</li> <li><code>name</code>: Lab identifier (auto-generated if None).</li> </ul>"},{"location":"api/lab/#methods","title":"Methods","text":""},{"location":"api/lab/#run_experiment","title":"<code>run_experiment</code>","text":"<p>Execute pipeline evaluation with CV and track results.</p> <pre><code>def run_experiment(\n    self,\n    pipeline: Pipeline,\n    eval_overfitting : bool = True,      # if True, overfitting will be evaluated\n    store_preds : bool = True,           # if True, predictions will be stored\n    verbose : bool = True,               # if True, progress will be printed\n    compare_against: int | None = None,  # id of the experiment to compare against\n    auto_mode : bool = False             # if True, the best experiment will be automatically updated if all criteria are met\n)\n</code></pre>"},{"location":"api/lab/#multi_run_experiment","title":"<code>multi_run_experiment</code>","text":"<p>Execute multiple experiments sequentially.</p> <pre><code>def multi_run_experiment(\n    self,\n    pipelines: List[Pipeline],\n    eval_overfitting : bool = True,      # if True, overfitting will be evaluated\n    store_preds : bool = True,           # if True, predictions will be stored\n    verbose : bool = True,               # if True, progress will be printed\n    compare_against: int | None = None,  # id of the experiment to compare against\n    auto_mode : bool = False             # if True, the best experiment will be automatically updated if all criteria are met\n)\n</code></pre>"},{"location":"api/lab/#run_base_experiments","title":"<code>run_base_experiments</code>","text":"<p>Run suite of baseline models for quick benchmarking.</p> <pre><code>def run_base_experiments(\n    self, \n    features: str, \n    preprocess_pipe : Pipeline | None = None,  # transformer-only pipeline to apply to features\n    eval_overfitting: bool = True,             # if True, overfitting will be evaluated\n    store_preds: bool = True,                   # if True, predictions will be stored\n    verbose: bool = True,                       # if True, progress will be printed\n    compare_against: int | None = None,         # id of the experiment to compare against\n    problem_type: str = 'regression'            # 'regression' or 'classification'\n)\n</code></pre>"},{"location":"api/lab/#hpo","title":"<code>hpo</code>","text":"<p>Hyperparameter optimization via grid or random search.</p> <pre><code>def hpo(\n    self, \n    features : List[str], \n    params_list : Dict[str, List[float | int | str]], \n    estimator : SKlearnEstimator, \n    preprocessor : Pipeline | BaseTransformer = Identity(),  # transformer-only pipeline to apply to features\n    eval_overfitting : bool = True,             # if True, overfitting will be evaluated\n    store_preds : bool = True,                   # if True, predictions will be stored\n    verbose : bool = True,                       # if True, progress will be printed\n    compare_against: int | None = None,         # id of the experiment to compare against\n    search_type : str = 'grid',                  # 'grid' or 'random'\n    num_samples : int = 64,                      # number of samples for random search\n    random_state : int = 0\n)\n</code></pre>"},{"location":"api/lab/#retrieve_predictions","title":"<code>retrieve_predictions</code>","text":"<p>Load predictions from specified experiments.</p> <pre><code>def retrieve_predictions(self, experiment_ids = List[int], extra_features : List[str] = []) -&gt; pl.LazyFrame\n</code></pre>"},{"location":"api/lab/#compute_pvalue","title":"<code>compute_pvalue</code>","text":"<p>Compute permutation test p-value comparing two experiments.</p> <pre><code>def compute_pvalue(self, experiment_ids : Tuple[int, int], n_iters : int = 200, extra_features: List[str] = []) -&gt; float\n</code></pre>"},{"location":"api/lab/#permutation_feature_importance","title":"<code>permutation_feature_importance</code>","text":"<p>Compute permutation feature importance for each feature.</p> <pre><code>def permutation_feature_importance(\n    self, \n    pipeline : Pipeline, \n    features : List[str],\n    n_iters : int = 5, \n    verbose : bool = True      \n) -&gt; pl.DataFrame\n</code></pre>"},{"location":"api/lab/#recursive_permutation_feature_selection","title":"<code>recursive_permutation_feature_selection</code>","text":"<p>Recursively eliminate features with negative importance.</p> <pre><code>def recursive_permutation_feature_selection(\n    self, \n    estimator : SKlearnEstimator, \n    features : List[str], \n    preprocessor : Pipeline | BaseTransformer = Identity(), \n    n_iters : int = 5, \n    verbose : bool = True\n) -&gt; List[str]\n</code></pre>"},{"location":"api/lab/#run_experiment_on_test","title":"<code>run_experiment_on_test</code>","text":"<p>Compute performance metrics of a pipeline associated with an experiment on the test set.</p> <pre><code>def run_experiment_on_test(\n    self, \n    experiment_id : int, \n    eval_overfitting : bool = True, \n    store_preds : bool = True, \n    verbose : bool = True\n) -&gt; Dict[str, Union[float, List[float]]]\n</code></pre>"},{"location":"api/lab/#retrieve_pipeline","title":"<code>retrieve_pipeline</code>","text":"<p>Retrieve a pipeline related to an experiment.</p> <pre><code>def retrieve_pipeline(self, experiment_id : int) -&gt; Pipeline\n</code></pre>"},{"location":"api/lab/#show_best_score","title":"<code>show_best_score</code>","text":"<p>Show the stats related to the experiment with the best cv_mean_score.</p> <pre><code>def show_best_score(self) -&gt; pl.DataFrame\n</code></pre>"},{"location":"api/lab/#save_check_point","title":"<code>save_check_point</code>","text":"<p>Serialize current lab state to disk.</p> <pre><code>def save_check_point(self, check_point_name : str | None = None) -&gt; None\n</code></pre>"},{"location":"api/lab/#example-usage","title":"Example Usage","text":"<pre><code>from empml.lab import Lab, ComparisonCriteria\n# Assuming necessary components (downloader, metric, cv) are imported/defined\n\n# 1. Define Criteria\ncriteria = ComparisonCriteria(\n    n_folds_threshold=1,\n    pct_threshold=0.05\n)\n\n# 2. Initialize Lab\nlab = Lab(\n    train_downloader=my_train_downloader_object,\n    metric=my_metric_object,\n    cv_generator=my_cv_object,\n    target='target_variable',\n    comparison_criteria=criteria,\n    minimize=True,\n    name='experiment_lab_01'\n)\n\n# 3. Run Base Experiments\nlab.run_base_experiments(\n    features=['feature_A', 'feature_B'],\n    problem_type='classification'\n)\n\n# 4. View Best Results\nlab.show_best_score()\n</code></pre>"},{"location":"api/lab/#helper-functions","title":"Helper Functions","text":""},{"location":"api/lab/#restore_check_point","title":"<code>restore_check_point</code>","text":"<p>Load saved lab state from checkpoint.</p> <pre><code>def restore_check_point(lab_name : str, check_point_name : str) -&gt; Lab\n</code></pre>"},{"location":"api/metrics/","title":"empml.metrics","text":"Object Description <code>MSE</code> Mean Squared Error. <code>RMSE</code> Root Mean Squared Error. <code>MAE</code> Mean Absolute Error. <code>MSLE</code> Mean Squared Logarithmic Error. <code>RMSLE</code> Root Mean Squared Logarithmic Error. <code>MAPE</code> Mean Absolute Percentage Error. <code>WMAE</code> Weighted Mean Absolute Error. <code>Accuracy</code> Classification accuracy. <code>Precision</code> Precision for binary classification. <code>Recall</code> Recall (Sensitivity) for binary classification. <code>F1Score</code> F1 Score for binary classification. <code>Specificity</code> Specificity (True Negative Rate) for binary classification. <code>BalancedAccuracy</code> Balanced Accuracy for binary classification. <code>ROCAUC</code> Area Under the ROC Curve for binary classification."},{"location":"api/metrics/#mse","title":"MSE","text":"<p>Mean Squared Error.</p>"},{"location":"api/metrics/#methods","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (pl.col(target) - pl.col(preds)).pow(2).mean()\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#rmse","title":"RMSE","text":"<p>Root Mean Squared Error.</p>"},{"location":"api/metrics/#methods_1","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (pl.col(target) - pl.col(preds)).pow(2).mean().sqrt()\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#mae","title":"MAE","text":"<p>Mean Absolute Error.</p>"},{"location":"api/metrics/#methods_2","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (pl.col(target) - pl.col(preds)).abs().mean()\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#msle","title":"MSLE","text":"<p>Mean Squared Logarithmic Error. Uses log1p for numerical stability.</p>"},{"location":"api/metrics/#methods_3","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (\n        (pl.col(target).log1p() - pl.col(preds).log1p()).pow(2).mean()\n    )\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#rmsle","title":"RMSLE","text":"<p>Root Mean Squared Logarithmic Error. Uses log1p for numerical stability.</p>"},{"location":"api/metrics/#methods_4","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (\n        (pl.col(target).log1p() - pl.col(preds).log1p()).pow(2).mean().sqrt()\n    )\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#mape","title":"MAPE","text":"<p>Mean Absolute Percentage Error. Returns percentage value (0-100).</p>"},{"location":"api/metrics/#methods_5","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (\n        ((pl.col(target) - pl.col(preds)).abs() / pl.col(target).abs())\n        .mean() * 100\n    )\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#wmae","title":"WMAE","text":"<p>Weighted Mean Absolute Error. Computed as sum(|errors|) / sum(target).</p>"},{"location":"api/metrics/#methods_6","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (\n        (pl.col(target) - pl.col(preds)).abs().sum() / pl.col(target).sum()\n    )\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#accuracy","title":"Accuracy","text":"<p>Classification accuracy. Proportion of correct predictions.</p>"},{"location":"api/metrics/#methods_7","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (pl.col(target) == pl.col(preds)).mean()\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#precision","title":"Precision","text":"<p>Precision for binary classification. TP / (TP + FP).</p>"},{"location":"api/metrics/#methods_8","title":"Methods","text":"<pre><code>def __init__(self, positive_class: int = 1):\n    pass\n\ndef compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (\n        ((pl.col(preds) == self.positive_class) &amp; (pl.col(target) == self.positive_class)).sum() /\n        (pl.col(preds) == self.positive_class).sum()\n    )\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#recall","title":"Recall","text":"<p>Recall (Sensitivity) for binary classification. TP / (TP + FN).</p>"},{"location":"api/metrics/#methods_9","title":"Methods","text":"<pre><code>def __init__(self, positive_class: int = 1):\n    pass\n\ndef compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (\n        ((pl.col(preds) == self.positive_class) &amp; (pl.col(target) == self.positive_class)).sum() /\n        (pl.col(target) == self.positive_class).sum()\n    )\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#f1score","title":"F1Score","text":"<p>F1 Score for binary classification. Harmonic mean of precision and recall.</p>"},{"location":"api/metrics/#methods_10","title":"Methods","text":"<pre><code>def __init__(self, positive_class: int = 1):\n    pass\n\ndef compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    tp = ((pl.col(preds) == self.positive_class) &amp; (pl.col(target) == self.positive_class)).sum()\n    pred_pos = (pl.col(preds) == self.positive_class).sum()\n    actual_pos = (pl.col(target) == self.positive_class).sum()\n\n    precision = tp / pred_pos\n    recall = tp / actual_pos\n    f1 = 2 * (precision * recall) / (precision + recall)\n\n    return lf.select(f1).collect().item()\n</code></pre>"},{"location":"api/metrics/#specificity","title":"Specificity","text":"<p>Specificity (True Negative Rate) for binary classification. TN / (TN + FP).</p>"},{"location":"api/metrics/#methods_11","title":"Methods","text":"<pre><code>def __init__(self, positive_class: int = 1):\n    pass\n\ndef compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    metric_expr = (\n        ((pl.col(preds) != self.positive_class) &amp; (pl.col(target) != self.positive_class)).sum() /\n        (pl.col(target) != self.positive_class).sum()\n    )\n    return lf.select(metric_expr).collect().item()\n</code></pre>"},{"location":"api/metrics/#balancedaccuracy","title":"BalancedAccuracy","text":"<p>Balanced Accuracy for binary classification. (Recall + Specificity) / 2.</p>"},{"location":"api/metrics/#methods_12","title":"Methods","text":"<pre><code>def __init__(self, positive_class: int = 1):\n    pass\n\ndef compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    sensitivity = (\n        ((pl.col(preds) == self.positive_class) &amp; (pl.col(target) == self.positive_class)).sum() /\n        (pl.col(target) == self.positive_class).sum()\n    )\n    specificity = (\n        ((pl.col(preds) != self.positive_class) &amp; (pl.col(target) != self.positive_class)).sum() /\n        (pl.col(target) != self.positive_class).sum()\n    )\n    balanced_acc = (sensitivity + specificity) / 2\n\n    return lf.select(balanced_acc).collect().item()\n</code></pre>"},{"location":"api/metrics/#rocauc","title":"ROCAUC","text":"<p>Area Under the ROC Curve for binary classification. Requires probability scores.</p>"},{"location":"api/metrics/#methods_13","title":"Methods","text":"<pre><code>def compute_metric(self, lf: pl.LazyFrame, target: str, preds: str) -&gt; float:\n    # Collect data and convert to numpy for sklearn computation\n    df = lf.select([pl.col(target), pl.col(preds)]).collect()\n    y_true = df[target].to_numpy()\n    y_scores = df[preds].to_numpy()\n\n    from sklearn.metrics import roc_auc_score\n    return roc_auc_score(y_true, y_scores)\n</code></pre>"},{"location":"api/pipeline/","title":"empml.pipeline","text":"Object Description <code>Pipeline</code> Custom pipeline for chaining transformers and an optional final estimator."},{"location":"api/pipeline/#pipeline","title":"Pipeline","text":"<p>Custom pipeline for chaining transformers and an optional final estimator.</p>"},{"location":"api/pipeline/#methods","title":"Methods","text":"<pre><code>def __init__(self, steps: list[tuple[str, Union[BaseTransformer, BaseEstimator, 'Pipeline']]], name : str = '', description : str = ''):\n    \"\"\"\n    Parameters:\n    -----------\n    steps : list of tuples\n        List of (name, transformer/estimator/pipeline) tuples in the order they should be applied.\n        If the last step is an estimator, the pipeline will support predict().\n        If all steps are transformers (or pipelines acting as transformers), the pipeline \n        will support transform().\n    \"\"\"\n    pass\n\ndef fit(self, lf: pl.LazyFrame, **fit_params):\n    \"\"\"\n    Fit all transformers and the final estimator (if present).\n\n    Parameters:\n    -----------\n    lf : pl.LazyFrame\n        Training data\n    **fit_params : dict\n        Parameters to pass to the final estimator's fit method\n    \"\"\"\n    pass\n\ndef transform(self, lf: pl.LazyFrame) -&gt; pl.LazyFrame:\n    \"\"\"\n    Apply all transformers sequentially.\n    Only available for transformer-only pipelines.\n\n    Parameters:\n    -----------\n    lf : pl.LazyFrame\n        Data to transform\n\n    Returns:\n    --------\n    pl.LazyFrame\n        Transformed data\n    \"\"\"\n    if not self._is_transformer_only:\n        raise ValueError(\n            \"transform() is only available for transformer-only pipelines. \"\n            \"This pipeline has an estimator as the final step. Use predict() instead.\"\n        )\n\n    lf_transformed = lf\n    for name, step in self.steps:\n        if isinstance(step, Pipeline):\n            lf_transformed = step.transform(lf_transformed)\n        else:\n            lf_transformed = step.transform(lf_transformed)\n\n    return lf_transformed\n\ndef fit_transform(self, lf: pl.LazyFrame) -&gt; pl.LazyFrame:\n    \"\"\"\n    Fit and transform in one step.\n    Only available for transformer-only pipelines.\n    \"\"\"\n    pass\n\ndef predict(self, lf: pl.LazyFrame) -&gt; np.ndarray:\n    \"\"\"\n    Apply all transformers and predict with the final estimator.\n    Only available for pipelines with an estimator as the final step.\n\n    Parameters:\n    -----------\n    lf : pl.LazyFrame\n        Data to predict on\n\n    Returns:\n    --------\n    np.ndarray\n        Predictions\n    \"\"\"\n    pass\n\ndef fit_predict(self, lf: pl.LazyFrame, **fit_params) -&gt; np.ndarray:\n    \"\"\"\n    Fit the pipeline and return predictions on the same data.\n    Only available for pipelines with an estimator.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/pipeline/#example-usage-transformer-only","title":"Example Usage (Transformer-only)","text":"<pre><code>from empml.pipeline import Pipeline\nfrom empml.transformers import AvgFeatures, MaxFeatures\nimport polars as pl\n\n# Create a sample LazyFrame\ndata = pl.DataFrame({\n    \"f1\": [1, 2, 3],\n    \"f2\": [4, 5, 6],\n    \"target\": [0, 1, 0]\n}).lazy()\n\n# Define a pipeline with only transformers\npreprocessing_pipeline = Pipeline(steps=[\n    ('avg_f1_f2', AvgFeatures(features=['f1', 'f2'], new_feature='avg_f1_f2')),\n    ('max_f1_f2', MaxFeatures(features=['f1', 'f2'], new_feature='max_f1_f2'))\n], name='Preprocessing', description='Feature Engineering Pipeline')\n\n# transform data\nprocessed_data = preprocessing_pipeline.fit_transform(data)\n\n# Collect results\nprocessed_data.collect()\n</code></pre>"},{"location":"api/transformers/","title":"empml.transformers","text":"Object Description <code>Identity</code> Pass-through transformer. <code>AvgFeatures</code> Compute mean across multiple features. <code>MaxFeatures</code> Compute max across multiple features. <code>MinFeatures</code> Compute min across multiple features. <code>StdFeatures</code> Compute standard deviation across multiple features. <code>MedianFeatures</code> Compute median across multiple features. <code>ModuleFeatures</code> Compute modulus of features. <code>MeanTargetEncoder</code> Target encoding using mean. <code>StdTargetEncoder</code> Target encoding using standard deviation. <code>MaxTargetEncoder</code> Target encoding using max. <code>MinTargetEncoder</code> Target encoding using min. <code>MedianTargetEncoder</code> Target encoding using median. <code>KurtTargetEncoder</code> Target encoding using kurtosis. <code>SkewTargetEncoder</code> Target encoding using skewness. <code>OrdinalEncoder</code> Encode categorical features as ordinal integers. <code>DummyEncoder</code> One-hot encode categorical features. <code>StandardScaler</code> Standardize features by removing the mean and scaling to unit variance. <code>MinMaxScaler</code> Transform features by scaling each feature to a given range. <code>Log1pFeatures</code> Apply log1p transformation. <code>Expm1Features</code> Apply expm1 transformation. <code>PowerFeatures</code> Apply power transformation. <code>InverseFeatures</code> Apply inverse transformation (1/x). <code>SimpleImputer</code> Impute missing values. <code>FillNulls</code> Fill null values with a specific strategy. <code>GenerateLags</code> Generate lag features for time series data."},{"location":"api/transformers/#identity","title":"Identity","text":"<p>Pass-through transformer.</p>"},{"location":"api/transformers/#avgfeatures","title":"AvgFeatures","text":"<p>Compute mean across multiple features.</p>"},{"location":"api/transformers/#maxfeatures","title":"MaxFeatures","text":"<p>Compute max across multiple features.</p>"},{"location":"api/transformers/#minfeatures","title":"MinFeatures","text":"<p>Compute min across multiple features.</p>"},{"location":"api/transformers/#stdfeatures","title":"StdFeatures","text":"<p>Compute standard deviation across multiple features.</p>"},{"location":"api/transformers/#medianfeatures","title":"MedianFeatures","text":"<p>Compute median across multiple features.</p>"},{"location":"api/transformers/#modulefeatures","title":"ModuleFeatures","text":"<p>Compute modulus of features.</p>"},{"location":"api/transformers/#meantargetencoder","title":"MeanTargetEncoder","text":"<p>Target encoding using mean.</p>"},{"location":"api/transformers/#stdtargetencoder","title":"StdTargetEncoder","text":"<p>Target encoding using standard deviation.</p>"},{"location":"api/transformers/#maxtargetencoder","title":"MaxTargetEncoder","text":"<p>Target encoding using max.</p>"},{"location":"api/transformers/#mintargetencoder","title":"MinTargetEncoder","text":"<p>Target encoding using min.</p>"},{"location":"api/transformers/#mediantargetencoder","title":"MedianTargetEncoder","text":"<p>Target encoding using median.</p>"},{"location":"api/transformers/#kurttargetencoder","title":"KurtTargetEncoder","text":"<p>Target encoding using kurtosis.</p>"},{"location":"api/transformers/#skewtargetencoder","title":"SkewTargetEncoder","text":"<p>Target encoding using skewness.</p>"},{"location":"api/transformers/#ordinalencoder","title":"OrdinalEncoder","text":"<p>Encode categorical features as ordinal integers.</p>"},{"location":"api/transformers/#dummyencoder","title":"DummyEncoder","text":"<p>One-hot encode categorical features.</p>"},{"location":"api/transformers/#standardscaler","title":"StandardScaler","text":"<p>Standardize features by removing the mean and scaling to unit variance.</p>"},{"location":"api/transformers/#minmaxscaler","title":"MinMaxScaler","text":"<p>Transform features by scaling each feature to a given range.</p>"},{"location":"api/transformers/#log1pfeatures","title":"Log1pFeatures","text":"<p>Apply log1p transformation.</p>"},{"location":"api/transformers/#expm1features","title":"Expm1Features","text":"<p>Apply expm1 transformation.</p>"},{"location":"api/transformers/#powerfeatures","title":"PowerFeatures","text":"<p>Apply power transformation.</p>"},{"location":"api/transformers/#inversefeatures","title":"InverseFeatures","text":"<p>Apply inverse transformation (1/x).</p>"},{"location":"api/transformers/#simpleimputer","title":"SimpleImputer","text":"<p>Impute missing values.</p>"},{"location":"api/transformers/#fillnulls","title":"FillNulls","text":"<p>Fill null values with a specific strategy.</p>"},{"location":"api/transformers/#generatelags","title":"GenerateLags","text":"<p>Generate lag features for time series data.</p>"},{"location":"api/wrappers/","title":"empml.wrappers","text":"Object Description <code>SKlearnWrapper</code> Wraps sklearn-like estimators for Polars LazyFrames. <code>TorchWrapper</code> Wrapper for PyTorch modules compatible with Polars LazyFrames."},{"location":"api/wrappers/#sklearnwrapper","title":"SKlearnWrapper","text":"<p>Wraps sklearn-like estimators for Polars LazyFrames.</p>"},{"location":"api/wrappers/#methods","title":"Methods","text":"<pre><code>def __init__(self, estimator: SKlearnEstimator, features: List[str], target: str):\n    pass\n\ndef fit(self, lf: pl.LazyFrame, **fit_kwargs):\n    \"\"\"Fit the wrapped estimator using Polars LazyFrame.\"\"\"\n    X = lf.select(self.features).collect().to_numpy()\n    y = lf.select(self.target).collect().to_series().to_numpy()\n\n    self.estimator.fit(X, y, **fit_kwargs)\n    return self\n\ndef predict(self, lf: pl.LazyFrame) -&gt; np.ndarray:\n    \"\"\"Predict using the wrapped estimator with Polars LazyFrame.\"\"\"\n    X = lf.select(self.features).collect().to_numpy()\n    return self.estimator.predict(X)\n\ndef predict_proba(self, lf: pl.LazyFrame) -&gt; np.ndarray:\n    \"\"\"\n    Predict class probabilities using the wrapped estimator with Polars LazyFrame.\n\n    Only available if the wrapped estimator has a predict_proba method.\n    \"\"\"\n    X = lf.select(self.features).collect().to_numpy()\n    return self.estimator.predict_proba(X)\n</code></pre>"},{"location":"api/wrappers/#torchwrapper","title":"TorchWrapper","text":"<p>Wrapper for PyTorch modules compatible with Polars LazyFrames.</p>"},{"location":"api/wrappers/#methods_1","title":"Methods","text":"<pre><code>def __init__(\n    self,\n    module: type[nn.Module],\n    features: List[str],\n    target: str,\n    task: str = 'regression',\n    # Module architecture parameters\n    input_dim: Optional[int] = None,\n    hidden_layers: Optional[List[int]] = None,\n    output_dim: Optional[int] = None,\n    # Skorch training parameters\n    max_epochs: int = 10,\n    lr: float = 0.01,\n    batch_size: int = 128,\n    optimizer: Any = None,\n    criterion: Any = None,\n    # Skorch regularization &amp; training\n    train_split: Any = None,\n    callbacks: Optional[List] = None,\n    warm_start: bool = False,\n    verbose: int = 0,\n    # Skorch device &amp; performance\n    device: str = 'cpu',\n    # Skorch iterator settings\n    iterator_train: Any = None,\n    iterator_train__shuffle: bool = True,\n    iterator_train__num_workers: int = 0,\n    iterator_valid: Any = None,\n    iterator_valid__shuffle: bool = False,\n    # Additional skorch parameters (passed as **kwargs to NeuralNet)\n    **kwargs\n):\n    pass\n\ndef fit(self, lf: pl.LazyFrame, **fit_kwargs):\n    \"\"\"\n    Fit the wrapped PyTorch model using Polars LazyFrame.\n\n    Automatically converts data to float32 as required by PyTorch and creates\n    the skorch estimator on first call.\n    \"\"\"\n    pass\n\ndef predict(self, lf: pl.LazyFrame) -&gt; np.ndarray:\n    \"\"\"\n    Predict using the wrapped PyTorch model with Polars LazyFrame.\n\n    Automatically converts input to float32 and flattens output for regressors.\n    \"\"\"\n    pass\n\ndef predict_proba(self, lf: pl.LazyFrame) -&gt; np.ndarray:\n    \"\"\"\n    Predict class probabilities using the wrapped PyTorch classifier.\n\n    Only available for classification tasks. Automatically converts input to float32.\n    \"\"\"\n    pass\n</code></pre>"}]}